{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f901de8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Intro to common CNN APIs**\n",
    "此份程式碼會介紹在 CNN model 當中常使用的 Layers。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c68f4a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 本章節大綱\n",
    "* [Conv2D( filters, kernel_size, strides, use_bias)](#Conv2D)\n",
    "  * [use_bias](#use-bias)\n",
    "  * [Multi-Channels](#Multi-Channels-with-1-Filter)\n",
    "  * [filters](#filters)\n",
    "  * [kernel_size](#kernel-_-size)\n",
    "  * [strides](#strides)\n",
    "* [Flatten](#Flatten)\n",
    "* [Padding](#Padding)\n",
    "* [Pooling](#Pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80560b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下載課程所需檔案\n",
    "!wget -q \"https://github.com/TA-aiacademy/course_3.0/releases/download/CVCNN_Data/cnn_part2_data.zip\"\n",
    "!unzip -q cnn_part2_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.array([[0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 1, 1, 0],\n",
    "                      [0, 1, 1, 1, 1, 0],\n",
    "                      [0, 0, 1, 0, 1, 0],\n",
    "                      [0, 0, 0, 1, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d7d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77681b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = input_img[np.newaxis, ..., np.newaxis]\n",
    "print(input_img.shape)\n",
    "print(\"(batch_size, height, width, channel)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72451b40",
   "metadata": {},
   "source": [
    "* ## Conv2D\n",
    "![](https://i.imgur.com/ziscEhS.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d353c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_init(shape, dtype=None):\n",
    "    filter_init = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]], dtype='float32')\n",
    "    # height, width, channel, filters\n",
    "    filter_init = filter_init.reshape((3, 3, 1, 1))\n",
    "    return tf.Variable(filter_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7bb0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_result = Conv2D(filters=1, kernel_size=(3, 3), strides=(1, 1),\n",
    "                     kernel_initializer=kernel_init)(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef44465",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_result = conv_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9260331",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conv_result.shape)\n",
    "print(conv_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb815bc",
   "metadata": {},
   "source": [
    "[(back...)](#Convolution2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2835a71c",
   "metadata": {},
   "source": [
    "* ## use bias\n",
    "![](https://i.imgur.com/3x4wMGO.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1016c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_result = Conv2D(filters=1, kernel_size=(3, 3), strides=(1, 1),\n",
    "                     kernel_initializer=kernel_init,\n",
    "                     use_bias=True,\n",
    "                     bias_initializer='ones')(input_img)\n",
    "\n",
    "bias_result = bias_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec6d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bias_result.shape)\n",
    "print(bias_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1ad5e",
   "metadata": {},
   "source": [
    "[(back...)](#Convolution2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f310c127",
   "metadata": {},
   "source": [
    "* ## Multi Channels with 1 Filter\n",
    "![](https://i.imgur.com/NCivRaq.gif)\n",
    "![](https://i.imgur.com/QEjI0jq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c27e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.load(\"./data/conv2d_multichannel_input.npy\")\n",
    "print(input_img.shape)\n",
    "print(input_img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d32be",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = input_img[np.newaxis, ...]\n",
    "print(input_img.shape)\n",
    "print(\"(Batch_size, Height, Width, Channel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d47433",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = input_img.astype(\"float32\")\n",
    "print(input_img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a196ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_init = np.load(\"./data/conv2d_multichannelfilter.npy\")\n",
    "print(filter_init.shape)\n",
    "print(\"(Height, Width, Channel, Num of Filters)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46366f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_init = tf.constant_initializer(filter_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b20b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multichannel = Conv2D(filters=1, kernel_size=(3, 3), strides=(1, 1),\n",
    "                      kernel_initializer=kernel_init)(input_img)\n",
    "\n",
    "multichannel = multichannel.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35339aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multichannel.shape)\n",
    "print(multichannel.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe90f00d",
   "metadata": {},
   "source": [
    "[(back...)](#Convolution2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0972b87a",
   "metadata": {},
   "source": [
    "* ## filters\n",
    "![](https://i.imgur.com/NCivRaq.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_filter_init = np.zeros((3, 3, 3, 8))\n",
    "for i in range(8):\n",
    "    multi_filter_init[:, :, :, i] = filter_init.squeeze()\n",
    "multi_filter_init = multi_filter_init.astype('float32')\n",
    "\n",
    "print(multi_filter_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241eef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_init = tf.constant_initializer(multi_filter_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "multifilter = Conv2D(8, (3, 3), strides=(1, 1),\n",
    "                     kernel_initializer=kernel_init)(input_img)\n",
    "\n",
    "multifilter = multifilter.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6af04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multifilter.shape)\n",
    "print(multifilter.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f352ce5e",
   "metadata": {},
   "source": [
    "[(back...)](#Convolution2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59caf228",
   "metadata": {},
   "source": [
    "* ## strides\n",
    "![](https://i.imgur.com/8XWHNqI.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58221fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.load(\"./data/conv2d_1channel_input.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bd52a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_init = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]], dtype='float32')\n",
    "filter_init = filter_init.reshape((3, 3, 1, 1))\n",
    "kernel_init = tf.constant_initializer(filter_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b73eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stride_result = Conv2D(1, (3, 3), strides=(2, 2),\n",
    "                       kernel_initializer=kernel_init)(input_img)\n",
    "\n",
    "stride_result = stride_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bf1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stride_result.shape)\n",
    "print(stride_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fb2f7a",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/2XmNAct.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb569f",
   "metadata": {},
   "source": [
    "# Flatten\n",
    "\n",
    "* [Way1-Reshape](#Way1---Reshape)\n",
    "* [Way2-Flatten](#Way2---Flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1e7030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Flatten, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8452c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img1 = np.array([[0, 1, 2, 3],\n",
    "                       [4, 5, 6, 7],\n",
    "                       [8, 9, 10, 11],\n",
    "                       [12, 13, 14, 15]], dtype='float32')\n",
    "input_img1 = input_img1[np.newaxis, ..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d98b7a4",
   "metadata": {},
   "source": [
    "* ## Way1 - Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_result = Reshape(target_shape=(-1,))(input_img1)\n",
    "reshape_result = reshape_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af18f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img1.shape)\n",
    "print(reshape_result.shape)\n",
    "print(reshape_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img2 = input_img1.copy()\n",
    "for _ in range(3):\n",
    "    input_img2 = np.concatenate([input_img2, input_img2], -1)\n",
    "print(input_img2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d62f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_result = Reshape(target_shape=(-1,))(input_img2)\n",
    "reshape_result = reshape_result.numpy()\n",
    "print(reshape_result.shape)\n",
    "print(reshape_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8940922",
   "metadata": {},
   "source": [
    "[(back...)](#Flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fab2e5",
   "metadata": {},
   "source": [
    "* ## Way2 - Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e4351c",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/MvwO4a0.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ff0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_result = Flatten()(input_img1)\n",
    "flatten_result = flatten_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d3c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img1.shape)\n",
    "print(flatten_result.shape)\n",
    "print(flatten_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cbaa74",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/FDh4d0L.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1777fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_result = Flatten()(input_img2)\n",
    "flatten_result = flatten_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e97cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flatten_result.shape)\n",
    "print(flatten_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9858fdcd",
   "metadata": {},
   "source": [
    "[(back...)](#Flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f9bee",
   "metadata": {},
   "source": [
    "# Padding\n",
    "\n",
    "* [padding='VALID'](#padding='VALID')\n",
    "* [padding='SAME'](#padding='SAME')\n",
    "* [ZeroPadding](#ZeroPadding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, ZeroPadding2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b923f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.array([[0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 1, 1, 0],\n",
    "                      [0, 1, 1, 1, 1, 0],\n",
    "                      [0, 0, 1, 0, 1, 0],\n",
    "                      [0, 0, 0, 1, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0]], dtype='float32')\n",
    "input_img = input_img[np.newaxis, ..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_init(shape, dtype=None):\n",
    "    filter_init = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "    filter_init = filter_init.reshape((3, 3, 1, 1))\n",
    "    return tf.Variable(filter_init, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cee328",
   "metadata": {},
   "source": [
    "* ## padding='VALID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d300c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nopad_result = Conv2D(1, (3, 3), padding='VALID',\n",
    "                      kernel_initializer=kernel_init)(input_img)\n",
    "\n",
    "nopad_result = nopad_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(nopad_result.shape)\n",
    "print(nopad_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e2dcd3",
   "metadata": {},
   "source": [
    "[(back...)](#Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cd777c",
   "metadata": {},
   "source": [
    "* ## padding='SAME'\n",
    "![](https://i.imgur.com/vZWnAvN.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b6f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_result = Conv2D(1, (3, 3), padding='SAME',\n",
    "                    kernel_initializer=kernel_init)(input_img)\n",
    "\n",
    "pad_result = pad_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b2f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(pad_result.shape)\n",
    "print(pad_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aed2e9",
   "metadata": {},
   "source": [
    "[(back...)](#Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cd7b04",
   "metadata": {},
   "source": [
    "## ZeroPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea96dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_padding = ZeroPadding2D(padding=(1, 1))(input_img)\n",
    "zero_result = Conv2D(1, (3, 3),\n",
    "                     kernel_initializer=kernel_init)(zero_padding)\n",
    "\n",
    "zero_padding = zero_padding.numpy()\n",
    "zero_result = zero_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce0d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(zero_padding.shape)\n",
    "print(zero_padding.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcec283",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zero_result.shape)\n",
    "print(zero_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb67bcf3",
   "metadata": {},
   "source": [
    "[(back...)](#Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e738bd8a",
   "metadata": {},
   "source": [
    "# Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a65bc0d",
   "metadata": {},
   "source": [
    "\n",
    "* [Average Pooling](#Average-Pooling)\n",
    "* [Max Pooling](#Max-Pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d4d7e",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/XZQtZC3.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa850e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import AveragePooling2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c9588",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.array([[1, 2, 2, 0],\n",
    "                      [1, 2, 3, 2],\n",
    "                      [3, 1, 3, 2],\n",
    "                      [0, 2, 0, 2]], dtype='float32').reshape((1, 4, 4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac25265a",
   "metadata": {},
   "source": [
    "* ## Average Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82163b",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/sDKe1To.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f802337",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_result = AveragePooling2D()(input_img)\n",
    "avg_result = avg_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2844449",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(avg_result.shape)\n",
    "print(avg_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9482529c",
   "metadata": {},
   "source": [
    "[(back...)](#Pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485dd32f",
   "metadata": {},
   "source": [
    "* ## Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b64082",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/HZhzUzN.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e89829",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_result = MaxPool2D()(input_img)\n",
    "max_result = max_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98236dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(max_result.shape)\n",
    "print(max_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8ed073",
   "metadata": {},
   "source": [
    "[(back...)](#Pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dc5b9e",
   "metadata": {},
   "source": [
    "# GlobalPooling\n",
    "\n",
    "* [Global Average Pooling](#Global-Average-Pooling)\n",
    "* [Global Max Pooling](#Global-Max-Pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8607fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import (GlobalAveragePooling2D,\n",
    "                                     GlobalMaxPooling2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86da18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.load(\"./data/globalpooling_input.npy\")[np.newaxis, ...]\n",
    "input_img = input_img.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b7417",
   "metadata": {},
   "source": [
    "* ## Global Average Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d801e7",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/c62Vie8.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad2608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(input_img[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f49a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_result = GlobalAveragePooling2D()(input_img)\n",
    "avg_result = avg_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f4c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_result.shape)\n",
    "print(avg_result.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ebf868",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img.mean((1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4253025e",
   "metadata": {},
   "source": [
    "[(back...)](#GlobalPooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a1119",
   "metadata": {},
   "source": [
    "* ## Global Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68986e57",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/XFNnWSe.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_result = GlobalMaxPooling2D()(input_img)\n",
    "max_result = max_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5759d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(input_img[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a269f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_result.shape)\n",
    "print(max_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d083809",
   "metadata": {},
   "source": [
    "[(back...)](#GlobalPooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6622454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
